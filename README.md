## Collecting Data from the Internet and Government Documents
### ASC 2019 Pre-Meeting Workshop
### [Neal Caren](http://nealcaren.org) (University of North Carolina, Chapel Hill)

This repository includes the materials for a short course on collecting data from the internet, including accessing APIs and web scraping, using Python.  While the course was taught in person, the materials are designed for self-paced, independent learning for social scientists with no background in Python. Each lesson includes exercises that can be completed within the notebook, along with answers.

Directions (starting from scratch):

1. Read the [setup notebook online](https://nbviewer.jupyter.org/github/nealcaren/ScrapingData/blob/master/Notebooks/1_Setup.ipynb). Follow the directions for installing Python.
2. [Download](https://github.com/nealcaren/ScrapingData/archive/master.zip) this repository by clicking on the green "Clone or DownloadâŒ„" button above. You may need to unzip the folder, depending on your operating system.
2. Using the instructions in the [setup file](https://nbviewer.jupyter.org/github/nealcaren/ScrapingData/blob/master/Notebooks/1_Setup.ipynb), start the Anaconda Navigator program, launch a Jupyter notebook, and navigate to the "Notebooks" folder that you downloaded in Step 2.
3. The first two notebooks (`2_Python.ipynb` and `3_Data.ipynb`) provide an introduction to working with Python.
3. The other numbered notebooks are the materials that were covered in class.
4. The `Bonus` notebooks detailed some additional techniques for data collection.

The lessons can also be completed [entirely online](https://mybinder.org/v2/gh/nealcaren/scrapingdata/master?filepath=Notebooks) without installing anything on your computer.

Let [me](mailto:neal.caren@gmail.com) know if you have any problems.

[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/nealcaren/scrapingdata/master?filepath=Notebooks)
